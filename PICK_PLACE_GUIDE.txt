â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         ğŸ¤– PICK-AND-PLACE SYSTEM - QUICK START GUIDE             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SYSTEM OVERVIEW
===============
Complete pick-and-place system with:
âœ“ Object detection by size, color, and shape (400 classes)
âœ“ Gripper control (open/close)
âœ“ Pick and place in left/right boxes
âœ“ Object stacking (small on large)
âœ“ Natural language commands via LLM
âœ“ Voice and text control
âœ“ RViz visualization + Real robot support

STARTING THE SYSTEM
===================

Terminal 1 - Launch RViz + MoveIt + Camera + YOLO:
  cd ~/dobot_rviz_ws
  source install/setup.bash
  ros2 launch launch/moveit_demo.launch.py

Terminal 2 - Start Pick-Place Controller (wait 10 seconds):
  cd ~/dobot_rviz_ws
  python3 dobot_llm_project/pick_place_controller.py
  â†’ Choose mode: 1 (Text) or 2 (Voice)

COMMAND EXAMPLES
================

Basic Pick and Place:
  "pick small red cube and place in left box"
  "pick large blue sphere and place in right box"
  "pick yellow cylinder and place right"
  "pick green and place left"

Stacking Objects:
  "stack small red on large blue"
  "place small yellow above large green"
  "stack small cube on large sphere"

Simple Movements:
  "home" - Return to home position
  "detect" - Move to detection pose
  "move left" / "move right" - Rotate base
  "move up" / "move down" - Raise/lower arm
  "move forward" / "move back" - Reach/retract

Gripper Control:
  "open gripper" - Release object
  "close gripper" - Grasp object

WORKFLOW EXPLANATION
====================

1. DETECTION PHASE
   - Robot moves to 'detect_pose' for good camera view
   - YOLO detects objects and publishes to /yolo/detections
   - Controller stores detected objects with confidence scores
   - Watch for: [INFO] ğŸ‘ï¸ Detected: small_red_cube (0.95)

2. PICK SEQUENCE
   Command: "pick small red cube"
   
   Steps:
   a) Find matching object from detections
   b) Move to detect pose
   c) Open gripper
   d) Approach object position
   e) Close gripper
   f) Lift object
   
   Output:
   [INFO] ğŸ¯ Starting pick sequence for: small red cube
   [INFO] Found: small_red_cube
   [INFO] ğŸ¯ Approaching object
   [INFO] ğŸ¤ Gripper CLOSE
   [INFO] ğŸ¯ Lifting object
   [INFO] âœ… Picked: small_red_cube

3. PLACE SEQUENCE
   Command: "place in left box"
   
   Steps:
   a) Move to target location (left_box/right_box)
   b) Lower arm
   c) Open gripper
   d) Retract
   e) Return to home
   
   Output:
   [INFO] ğŸ¯ Placing small_red_cube at left_box
   [INFO] ğŸ¯ Moving to left_box
   [INFO] ğŸ¯ Lowering
   [INFO] ğŸ¤ Gripper OPEN
   [INFO] ğŸ¯ Retracting
   [INFO] âœ… Placed small_red_cube at left_box

4. COMBINED TASK
   Command: "pick small red cube and place in left box"
   
   Executes full sequence automatically:
   detect â†’ approach â†’ grasp â†’ lift â†’ move â†’ place â†’ home

WORKSPACE LAYOUT
================

Top View (looking down):
```
          FRONT (camera view)
              â†‘
              
    [Left Box]     [Right Box]
        +               +
        
              â€¢  Robot Base
              
          BACK
```

Coordinate System:
- X: Forward/back (0.15-0.25m typical)
- Y: Left/right (Â±0.20m for boxes)
- Z: Height (0.05m table surface)

Joint Positions:
- home: [0, 0, 0, 0] - Upright neutral
- detect_pose: [0, 0.3, -0.2, 0] - Good camera angle
- left_box: [0.5, 0.3, 0, 0] - Approximate
- right_box: [-0.5, 0.3, 0, 0] - Approximate

OBJECT DETECTION
================

Supported Classes (400 total):
- Shapes: cube, cylinder, sphere, pyramid, cone, prism, hexagon, star, disk, torus
- Sizes: small, large
- Colors: red, green, blue, yellow, orange, purple, pink, cyan, magenta, lime,
          navy, teal, maroon, olive, brown, coral, turquoise, violet, indigo, gold

Model: ~/dobot_rviz_ws/dobot_llm_project/models/yolo_shapes_best.pt
Camera: USB camera at /dev/video0 (640x480 @ 30fps)
Confidence threshold: 0.25 (25%)

To verify detection:
  ros2 topic echo /yolo/detections

TESTING PROCEDURE
=================

1. Place Objects in View
   - Put colored objects in front of USB camera
   - Ensure good lighting
   - Wait for detection messages

2. Test Simple Pick
   Command: "detect"
   - Robot should move to detection pose
   - Verify objects visible in RViz camera view
   
   Command: "pick small red cube"
   - Watch robot approach (approximate position)
   - Gripper should close
   - Robot should lift

3. Test Place
   Command: "place in left box"
   - Robot should move to left side
   - Lower
   - Open gripper
   - Retract

4. Test Full Sequence
   Command: "pick small red cube and place in left box"
   - Full automatic sequence
   - Should return home after completion

5. Test Stacking
   Command: "stack small blue on large red"
   - Picks small blue object
   - Places on large red (center position)

TROUBLESHOOTING
===============

No Detections:
  - Check camera feed: ros2 topic hz /camera/image_raw
  - View camera: python3 view_camera.py
  - Verify USB camera connected: ls /dev/video0
  - Check lighting and object visibility

Robot Doesn't Move:
  - Verify MoveIt running: ros2 node list | grep move_group
  - Check joint states: ros2 topic echo /joint_states --once
  - Try simple command first: "home"

Wrong Object Selected:
  - Be more specific: "small red cube" vs just "cube"
  - Check what's detected: ros2 topic echo /yolo/detections
  - Only detected objects can be picked

Planning Fails:
  - Check joint limits not exceeded
  - Try "home" first to reset
  - Reduce movement distance

Gripper Not Working:
  - Gripper commands published to /gripper/command
  - For real robot, connect to dobot_driver
  - In RViz, gripper is simulated (no visual)

CURRENT LIMITATIONS
===================

âš ï¸  Object 3D positions are approximate (not using camera coordinates yet)
âš ï¸  Gripper is simulated (publishes commands but no physical gripper in URDF)
âš ï¸  Inverse kinematics not fully implemented (using preset joint positions)
âš ï¸  Real robot interface requires dobot_driver integration
âš ï¸  No collision detection with objects or boxes

NEXT ENHANCEMENTS
=================

â˜ Calculate actual 3D positions from camera + bounding boxes
â˜ Implement full IK solver for precise Cartesian positioning
â˜ Add gripper to URDF with proper visualization
â˜ Integrate with real Dobot Magician via dobot_driver
â˜ Add collision objects for boxes in planning scene
â˜ Implement visual servoing for precise alignment
â˜ Add force feedback for grasp verification

KEY TOPICS
==========

/yolo/detections - Object detection results
/joint_states - Current robot position
/gripper/command - Gripper open/close (Bool)
/camera/image_raw - Camera feed
/move_action - MoveIt planning action

ROS2 COMMANDS
=============

Check nodes:
  ros2 node list

Check topics:
  ros2 topic list

Monitor detections:
  ros2 topic echo /yolo/detections

Monitor gripper:
  ros2 topic echo /gripper/command

View joint states:
  ros2 topic echo /joint_states

EXAMPLE SESSION
===============

Terminal output:
```
ğŸ¤– Pick-and-Place Controller
Choose mode:
  1) Text commands
  2) Voice commands
Mode (1 or 2): 1

Command: detect
[INFO] ğŸ¯ Moving to detect_pose
[INFO] âœ… Movement complete!

Command: pick small red cube
[INFO] ğŸ‘ï¸  Detected: small_red_cube (0.87)
[INFO] ğŸ¯ Starting pick sequence for: small red cube
[INFO] Found: small_red_cube
[INFO] ğŸ¯ Moving to detect_pose
[INFO] âœ… Movement complete!
[INFO] ğŸ¤ Gripper OPEN
[INFO] ğŸ¯ Approaching object
[INFO] âœ… Movement complete!
[INFO] ğŸ¤ Gripper CLOSE
[INFO] ğŸ¯ Lifting object
[INFO] âœ… Movement complete!
[INFO] âœ… Picked: small_red_cube

Command: place in left box
[INFO] ğŸ¯ Placing small_red_cube at left_box
[INFO] ğŸ¯ Moving to left_box
[INFO] âœ… Movement complete!
[INFO] ğŸ¯ Lowering
[INFO] âœ… Movement complete!
[INFO] ğŸ¤ Gripper OPEN
[INFO] ğŸ¯ Retracting
[INFO] âœ… Movement complete!
[INFO] âœ… Placed small_red_cube at left_box

Command: home
[INFO] ğŸ¯ Moving to home
[INFO] âœ… Movement complete!

Command: exit
```

SUCCESS CRITERIA
================

âœ… Robot detects objects via YOLO
âœ… Parses natural language pick/place commands
âœ… Executes pick sequence (approach, grasp, lift)
âœ… Executes place sequence (move, lower, release)
âœ… Places in left/right boxes as commanded
âœ… Returns home after task completion
âœ… Gripper opens/closes on command
âœ… Handles stacking requests

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ‰ ADVANCED PICK-AND-PLACE SYSTEM READY!                        â•‘
â•‘  ğŸ“¦ Try: "pick small red cube and place in left box"            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
